{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1192499,"sourceType":"datasetVersion","datasetId":622510}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:27:23.666853Z","iopub.execute_input":"2025-10-12T16:27:23.667070Z","iopub.status.idle":"2025-10-12T16:27:25.027439Z","shell.execute_reply.started":"2025-10-12T16:27:23.667042Z","shell.execute_reply":"2025-10-12T16:27:25.026646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== 0) Setup (Kaggle) =====================\n!pip -q install -U transformers peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:27:25.029229Z","iopub.execute_input":"2025-10-12T16:27:25.029519Z","iopub.status.idle":"2025-10-12T16:28:56.015101Z","shell.execute_reply.started":"2025-10-12T16:27:25.029502Z","shell.execute_reply":"2025-10-12T16:28:56.014111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== 1) Imports & Env ======================\nimport os, warnings, numpy as np, pandas as pd, torch\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\nimport numpy as np\nimport pandas as pd\n\nimport transformers\nfrom transformers import (\n    AutoTokenizer, AutoModelForSequenceClassification,\n    TrainingArguments, Trainer\n)\nfrom peft import LoraConfig, get_peft_model\n\nprint(\"transformers==\", transformers.__version__)\nprint(\"torch==\", torch.__version__, \"| cuda:\", torch.cuda.is_available())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:28:56.016242Z","iopub.execute_input":"2025-10-12T16:28:56.016705Z","iopub.status.idle":"2025-10-12T16:29:19.973259Z","shell.execute_reply.started":"2025-10-12T16:28:56.016668Z","shell.execute_reply":"2025-10-12T16:29:19.972598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== 2) Model / Tokeniser ==================\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom peft import LoraConfig, get_peft_model, TaskType\n\nMODEL_NAME = \"ProsusAI/finbert\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\nid2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\nlabel2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n\ndef build_base_model():\n    return AutoModelForSequenceClassification.from_pretrained(\n        MODEL_NAME,\n        num_labels=3,\n        id2label=id2label,\n        label2id=label2id,\n    )\n\ndef build_lora_model():\n    base = build_base_model()\n    lora_cfg = LoraConfig(\n        task_type=TaskType.SEQ_CLS,\n        r=16, lora_alpha=32, lora_dropout=0.05,\n        target_modules=[\"query\",\"value\"],  \n        bias=\"none\",\n    )\n    return get_peft_model(base, lora_cfg)\ndef train_once(model, train_data, eval_data, out_dir, *, lr, bsz_train, bsz_eval, epochs):\n    args = TrainingArguments(\n        output_dir=out_dir,\n        learning_rate=lr,\n        per_device_train_batch_size=bsz_train,\n        per_device_eval_batch_size=bsz_eval,\n        num_train_epochs=epochs,\n        lr_scheduler_type=\"linear\",\n        optim=\"adamw_torch\",\n        logging_steps=100,\n        report_to=\"none\",\n        seed=42,\n        fp16=torch.cuda.is_available(),\n    )\n    trainer = Trainer(\n        model=model,\n        args=args,\n        train_dataset=train_data,\n        eval_dataset=eval_data,\n        tokenizer=tokenizer,\n        compute_metrics=compute_metrics,  \n    )\n    trainer.train()\n    metrics_val = trainer.evaluate(eval_data)\n    return trainer, metrics_val\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:29:19.974000Z","iopub.execute_input":"2025-10-12T16:29:19.974607Z","iopub.status.idle":"2025-10-12T16:29:20.965158Z","shell.execute_reply.started":"2025-10-12T16:29:19.974567Z","shell.execute_reply":"2025-10-12T16:29:20.964601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== 3) Load & Split Data ==================\nfilename = \"/kaggle/input/sentiment-analysis-for-financial-news/all-data.csv\"\ndf = pd.read_csv(\n    filename, names=[\"sentiment\", \"text\"],\n    encoding=\"ISO-8859-1\", engine=\"python\"\n)\n\nparts_train, parts_test = [], []\nfor s in [\"positive\", \"neutral\", \"negative\"]:\n    tr, te = train_test_split(\n        df[df.sentiment == s], train_size=300, test_size=300, random_state=42\n    )\n    parts_train.append(tr); parts_test.append(te)\n\nX_train = pd.concat(parts_train) \nX_test  = pd.concat(parts_test)\n\nused_idx = set(X_train.index) | set(X_test.index)\nX_eval = (df.loc[df.index.difference(used_idx)]\n            .groupby('sentiment', group_keys=False)\n            .apply(lambda x: x.sample(n=50, random_state=10, replace=True)))\n\nX_train = X_train.sample(frac=1, random_state=10).reset_index(drop=True)\nX_test  = X_test.reset_index(drop=True)\nX_eval  = X_eval.reset_index(drop=True)\n\nfor _df in [X_train, X_test, X_eval]:\n    _df[\"labels\"] = _df.sentiment.map(label2id).astype(\"int64\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:29:20.965830Z","iopub.execute_input":"2025-10-12T16:29:20.966069Z","iopub.status.idle":"2025-10-12T16:29:21.025248Z","shell.execute_reply.started":"2025-10-12T16:29:20.966051Z","shell.execute_reply":"2025-10-12T16:29:21.024746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== 4) Build HF Datasets ==================\ndef tok_fn(batch):\n    return tokenizer(\n        batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256\n    )\n\ntrain_data = Dataset.from_pandas(X_train).map(tok_fn, batched=True)\\\n    .remove_columns([\"text\",\"sentiment\"])\ntest_data  = Dataset.from_pandas(X_test).map(tok_fn, batched=True)\\\n    .remove_columns([\"text\",\"sentiment\"])\neval_data  = Dataset.from_pandas(X_eval).map(tok_fn, batched=True)\\\n    .remove_columns([\"text\",\"sentiment\"])\n\ncols = [\"input_ids\", \"attention_mask\", \"labels\"]\ntrain_data.set_format(\"torch\", columns=cols)\ntest_data.set_format(\"torch\",  columns=cols)\neval_data.set_format(\"torch\",  columns=cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:29:21.025942Z","iopub.execute_input":"2025-10-12T16:29:21.026185Z","iopub.status.idle":"2025-10-12T16:29:21.576179Z","shell.execute_reply.started":"2025-10-12T16:29:21.026164Z","shell.execute_reply":"2025-10-12T16:29:21.575407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== 5) Metrics ============================\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=1)\n    return {\n        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n        \"accuracy\": accuracy_score(labels, preds),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:29:21.577835Z","iopub.execute_input":"2025-10-12T16:29:21.578154Z","iopub.status.idle":"2025-10-12T16:29:21.582195Z","shell.execute_reply.started":"2025-10-12T16:29:21.578136Z","shell.execute_reply":"2025-10-12T16:29:21.581608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== 6)Train Full & LoRA =====================\n# Full fine-tuning\nprint(\"ðŸ”¹ Training FULL fine-tuning...\")\ntrainer_full, res_full = train_once(\n    model=build_base_model(),\n    train_data=train_data, eval_data=eval_data,\n    out_dir=f\"finetuned_full_{MODEL_NAME.split('/')[-1]}\",\n    lr=2e-5, bsz_train=8, bsz_eval=8, epochs=5\n)\nprint(f\"[FULL] val_f1={res_full['eval_f1']:.5f} | val_acc={res_full['eval_accuracy']:.5f}\")\n\n# LoRA fine-tuning\nprint(\"\\nðŸ”¹ Training LoRA fine-tuning...\")\ntrainer_lora, res_lora = train_once(\n    model=build_lora_model(),\n    train_data=train_data, eval_data=eval_data,\n    out_dir=f\"finetuned_lora_{MODEL_NAME.split('/')[-1]}\",\n    lr=1e-3, bsz_train=32, bsz_eval=64, epochs=5\n)\nprint(f\"[LoRA] val_f1={res_lora['eval_f1']:.5f} | val_acc={res_lora['eval_accuracy']:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:29:21.582954Z","iopub.execute_input":"2025-10-12T16:29:21.583275Z","iopub.status.idle":"2025-10-12T16:32:44.813978Z","shell.execute_reply.started":"2025-10-12T16:29:21.583249Z","shell.execute_reply":"2025-10-12T16:32:44.813360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== 7)Test & Compare on hold-out test set =====================\ndef eval_trainer(trainer, test_data, name=\"MODEL\"):\n    pred = trainer.predict(test_data)\n    y_true = pred.label_ids\n    y_pred = np.argmax(pred.predictions, axis=1)\n    acc = accuracy_score(y_true, y_pred)\n    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n    f1_weighted = f1_score(y_true, y_pred, average=\"weighted\")\n    print(f\"\\n===== {name} : Test Report =====\")\n    print(classification_report(y_true, y_pred, target_names=[id2label[i] for i in sorted(id2label)] , digits=4))\n    print(\"Confusion matrix:\")\n    print(confusion_matrix(y_true, y_pred, labels=sorted(id2label.keys())))\n    print(f\"Accuracy:    {acc:.4f}\")\n    print(f\"F1 (macro):  {f1_macro:.4f}\")\n    print(f\"F1 (weighted): {f1_weighted:.4f}\")\n    return {\"name\": name, \"accuracy\": acc, \"f1_macro\": f1_macro, \"f1_weighted\": f1_weighted}\n\nm_full = eval_trainer(trainer_full, test_data, name=\"FinBERT Full FT\")\nm_lora = eval_trainer(trainer_lora, test_data, name=\"FinBERT LoRA\")\n\ncmp_df = pd.DataFrame([m_full, m_lora]).set_index(\"name\")\nprint(\"\\n===== Summary (Test) =====\")\nprint(cmp_df.sort_values(\"f1_macro\", ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:32:44.814925Z","iopub.execute_input":"2025-10-12T16:32:44.815206Z","iopub.status.idle":"2025-10-12T16:32:58.527156Z","shell.execute_reply.started":"2025-10-12T16:32:44.815182Z","shell.execute_reply":"2025-10-12T16:32:58.526509Z"}},"outputs":[],"execution_count":null}]}